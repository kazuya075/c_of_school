{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import collections\n",
    "import sys\n",
    "import MeCab\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "カルメン \n",
      "\n",
      "芥川 龍之介 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "【 テキスト 中 に 現れる 記号 について 】 \n",
      "\n",
      "\n",
      "\n",
      "《 》 ： ルビ \n",
      "\n",
      "（ 例 ） 露台 \n",
      "\n",
      "\n",
      "\n",
      "： ルビ の 付く 文字 列 の 始まり を 特定 する 記号 \n",
      "\n",
      "（ 例 ） 革命 前 \n",
      "\n",
      "\n",
      "\n",
      "： 入力 者 注 　 主 に 外字 の 説明 や 、 傍点 の 位置 の 指定 \n",
      "\n",
      "（ 例 ） カゲキ 派 です から \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "　 革命 前 だっ た か 、 革命 後 だっ た か 、 ―― いや 、 あれ は 革命 前 で は ない 。 なぜ また 革命 前 で は ない か と 言え ば 、 僕 は 当時 小耳 に 挟ん だ ダンチェンコ の 洒落 を 覚え て いる から で ある 。 \n",
      "\n",
      "　 ある 蒸し暑い 雨 も よい の 夜 、 舞台 監督 の Ｔ 君 は 、 帝劇 の 露台 に 佇み ながら 、 炭酸 水 の コップ を 片手 に 詩人 の ダンチェンコ と 話し て い た 。 あの 亜麻 色 の 髪の毛 を し た 盲目 詩人 の ダンチェンコ と で ある 。 \n",
      "\n",
      "「 これ も やっぱり 時勢 です ね 。 はるばる 露西亜 の グランド ・ オペラ が 日本 の 東京 へ やって来る と 言う の は 。 」 \n",
      "\n",
      "「 それ は ボルシェヴィッキ は カゲキ 派 です から 。 」 \n",
      "\n",
      "　 この 問答 の あっ た の は 確か 初日 から 五 日 目 の 晩 、 ―― カルメン が 舞台 へ 登っ た 晩 で ある 。 僕 は カルメン に 扮する はず の イイナ・ブルスカアヤ に 夢中 に なっ て い た 。 イイナ は 目 の 大きい 、 小鼻 の 張っ た 、 肉感 の 強い 女 で ある 。 僕 は 勿論 カルメン に 扮する イイナ を 観る こと を 楽しみ に し て い た 、 が 、 第 一幕 が 上っ た の を 見る と 、 カルメン に 扮 し た の は イイ ナ で は ない 。 水色 の 目 を し た 、 鼻 の 高い 、 何とか 云う 貧相 な 女優 で ある 。 僕 は Ｔ 君 と 同じ ボックス に タキシイド の 胸 を 並べ ながら 、 落胆 し ない 訣 に は 行か なかっ た 。 \n",
      "\n",
      "「 カルメン は 僕 等 の イイナ じゃ ない ね 。 」 \n",
      "\n",
      "「 イイナ は 今夜 は 休み だ そう だ 。 その 原因 が また 頗る ロマンティック で ね 。 ―― 」 \n",
      "\n",
      "「 どう し た ん だ ？ 」 \n",
      "\n",
      "「 何とか 云う 旧 帝国 の 侯爵 が 一 人 、 イイナ の あと を 追っかけ て 来 て ね 、 おととい 東京 へ 着い た ん だ そう だ 。 ところが イイナ は いつのまにか 亜米利加 人 の 商人 の 世話 に なっ て いる 。 そいつ を 見 た 侯爵 は 絶望 し た ん だ ね 、 ゆうべ ホテル の 自分 の 部屋 で 首 を 縊 って 死ん じまっ た ん だ そう だ 。 」 \n",
      "\n",
      "　 僕 は この 話 を 聞い て いる うち に 、 ある 場景 を 思い出し た 。 それ は 夜 の 更け た ホテル の 一室 に 大勢 の 男女 に 囲ま れ た まま 、 トランプ を 弄ん で いる イイナ で ある 。 黒 と 赤 と の 着物 を 着 た イイ ナ は ジプシイ 占い を し て いる と 見え 、 Ｔ 君 に ほほ笑みかけ ながら 、 「 今度 は あなた の 運 を 見 て 上げ ましょ う 」 と 言っ た 。 （ あるいは 言っ た の だ と 云う こと で ある 。 ダア 以外 の 露西亜 語 を 知ら ない 僕 は 勿論 十 二 箇国 の 言葉 に 通じ た Ｔ 君 に 翻訳 し て 貰う ほか は ない 。 ） それ から トランプ を まくっ て 見 た 後 、 「 あなた は あの 人 より も 幸福 です よ 。 あなた の 愛する 人 と 結婚 出来 ます 」 と 言っ た 。 あの 人 と 云う の は イイ ナ の 側 に 誰 か と 話し て い た 露西亜 人 で ある 。 僕 は 不幸 に も 「 あの 人 」 の 顔 だの 服装 だ の を 覚え て い ない 。 わずか に 僕 が 覚え て いる の は 胸 に 挿し て い た 石竹 だけ で ある 。 イイナ の 愛 を 失っ た ため に 首 を 縊 って 死ん だ と 云う の は あの 晩 の 「 あの 人 」 で は なかっ た で あろ う か ？ … … \n",
      "\n",
      "「 それ じゃ 今夜 は 出 ない はず だ 。 」 \n",
      "\n",
      "「 好い加減 に 外 へ 出 て 一杯 やる か ？ 」 \n",
      "\n",
      "Ｔ 君 も 勿論 イイ ナ 党 で ある 。 \n",
      "\n",
      "「 まあ 、 もう 一幕 見 て 行こ う じゃ ない か ？ 」 \n",
      "\n",
      "　 僕 等 が ダンチェンコ と 話し たり し た の は 恐らくは この 幕 合い だっ た の で あろ う 。 \n",
      "\n",
      "　 次 の 幕 も 僕 等 に は 退屈 だっ た 。 しかし 僕 等 が 席 について まだ 五 分 と たた ない うち に 外国 人 が 五 六 人 ちょうど 僕 等 の 正面 に 当る 向う側 の ボックス へ はいっ て 来 た 。 しかも 彼等 の まっ 先 に 立っ た の は 紛れ も ない イイナ・ブルスカアヤ で ある 。 イイナ は ボックス の 一番 前 に 坐り 、 孔雀 の 羽根 の 扇 を 使い ながら 、 悠々 と 舞台 を 眺め 出し た 。 のみ なら ず 同伴 の 外国 人 の 男女 と （ その 中 に は 必ず 彼女 の 檀那 の 亜米利加 人 も 交っ て い た の で あろ う 。 ） 愉快 そう に 笑っ たり 話し たり し 出し た 。 \n",
      "\n",
      "「 イイナ だ ね 。 」 \n",
      "\n",
      "「 うん 、 イイナ だ 。 」 \n",
      "\n",
      "　 僕 等 は とうとう 最後 の 幕 まで 、 ―― カルメン の 死骸 を 擁し た ホセ が 、 「 カルメン ！ 　 カルメン ！ 」 と 慟哭 する まで 僕 等 の ボックス を 離れ なかっ た 。 それ は 勿論 舞台 より も イイナ・ブルスカアヤ を 見 て い た ため で ある 。 この 男 を 殺し た こと を 何とも 思っ て い ない らしい 露西亜 の カルメン を 見 て い た ため で ある 。 \n",
      "\n",
      "\n",
      "\n",
      "　 　 　 　 　 　 　 × 　 　 　 　 　 　 　 　 　 　 × 　 　 　 　 　 　 　 　 　 　 × \n",
      "\n",
      "\n",
      "\n",
      "　 それから 二 三 日 たっ た ある 晩 、 僕 は ある レストラン の 隅 に Ｔ 君 と テエブル を 囲ん で い た 。 \n",
      "\n",
      "「 君 は イイナ が あの 晩 以来 、 確か 左 の 薬指 に 繃帯 し て い た のに 気 が つい て いる かい ？ 」 \n",
      "\n",
      "「 そう 云え ば 繃帯 し て い た よう だ ね 。 」 \n",
      "\n",
      "「 イイナ は あの 晩 ホテル へ 帰る と 、 … … 」 \n",
      "\n",
      "「 駄目 だ よ 、 君 、 それ を 飲ん じゃ 。 」 \n",
      "\n",
      "　 僕 は Ｔ 君 に 注意 し た 。 薄い 光 の さし た グラス の 中 に は まだ 小さい 黄金虫 が 一 匹 、 仰向け に なっ て もがい て い た 。 Ｔ 君 は 白 葡萄 酒 を 床 へ こぼし 、 妙 な 顔 を し て つけ加え た 。 \n",
      "\n",
      "「 皿 を 壁 へ 叩きつけ て ね 、 その また 欠片 を カスタネット の 代り に し て ね 、 指 から 血 の 出る の も かまわ ず に ね 、 … … 」 \n",
      "\n",
      "「 カルメン の よう に 踊っ た の かい ？ 」 \n",
      "\n",
      "　 そこ へ 僕 等 の 興奮 と は 全然 つり合わ ない 顔 を し た 、 頭 の 白い 給仕 が 一 人 、 静 に 鮭 の 皿 を 運ん で 来 た 。 … … \n",
      "\n",
      "（ 大正 十 五 年 四月 十 日 ） \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "　 　 　 1987 （ 昭和 62 ） 年 3 月 24 日 第 1 刷 発行 \n",
      "\n",
      "　 　 　 1993 （ 平成 5 ） 年 2 月 25 日 第 6 刷 発行 \n",
      "\n",
      "底本 の 親 本 ： 「 筑摩 全集 類聚 版 芥川 龍之介 全集 」 筑摩書房 \n",
      "\n",
      "　 　 　 1971 （ 昭和 46 ） 年 3 月 ～ 1971 （ 昭和 46 ） 年 11 月 \n",
      "\n",
      "入力 ： j . utiyama \n",
      "\n",
      "校正 ： 田尻 幹 二 \n",
      "\n",
      "1999 年 1 月 27 日 公開 \n",
      "\n",
      "2004 年 3 月 7 日 修正 \n",
      "\n",
      "青空 文庫 作成 ファイル ： \n",
      "\n",
      "この ファイル は 、 インターネット の 図書館 、 青空 文庫 （ http :// www . aozora . gr . jp /） で 作ら れ まし た 。 入力 、 校正 、 制作 に あたっ た の は 、 ボランティア の 皆さん です 。 \n",
      "\n",
      "各単語の出現回数 [('の', 87), ('た', 57), ('。', 52), ('は', 50), ('、', 48), ('に', 43), ('を', 39), ('て', 31), ('で', 26), ('と', 24), ('「', 23), ('」', 23), ('僕', 18), ('だ', 17), ('ある', 17), ('し', 17), ('が', 15), ('ない', 14), ('い', 14), ('イイナ', 13)]\n",
      "単語の異なり数 456\n",
      "総数 1410\n"
     ]
    }
   ],
   "source": [
    "m = MeCab.Tagger (\"-Owakati\")#分かち書き\n",
    "list=[]\n",
    "    \n",
    "for line in open('carmen.txt', 'r'):## ファイルを1行ずつ読み込み、出力する\n",
    "    #文字コード\n",
    "    #re.sub を使用して正規表現で文字列を置換する\n",
    "    #置換後の文字列 = re.sub(正規表現, 置換する文字列, 置換される文字列 [, 置換回数])\n",
    "    #正規表現で日本語を扱う時uを使う.rでそのまま    u'[ぁ-ん]' ,r'ab+'\n",
    "    #uなくてもいい\n",
    "    line = re.sub('《[^》]+》', '', line)#《》を消す\n",
    "    line = re.sub(u'｜', '', line)#｜を消す\n",
    "    line = re.sub(u'［.+?］', '', line)#[]を消す\n",
    "\n",
    "        # ヘッダ部分の削除\n",
    "    line = re.sub(u'-----[\\s\\S]*-----', '', line)\n",
    "    # フッタ部分の削除\n",
    "    line = re.split(u'底本：',line)[0]\n",
    "    \n",
    "    # 改行の削除\n",
    "    line = re.sub(u'\\n', '', line)\n",
    "    line = re.sub(u'\\r', '', line)\n",
    "    \n",
    "    words = m.parse(line)#m.parseで読み込んだ文章を分解\n",
    "    print(words)\n",
    "                            # words.split() 区切り文字でリストに\n",
    "    list.extend(words.split())#リストの連結 \n",
    "    \n",
    "    #word_tokenize() で単語に分解．\n",
    "    #list.extend(word_tokenize(words))#リストの連結 \n",
    "\n",
    "c = collections.Counter(list)#単語の出現個数をカウント\n",
    "print(\"各単語の出現回数\",c.most_common(20))#表示 most_common()メソッドに引数nを指定すると、出現回数の多いn要素のみを返す。\n",
    "print(\"単語の異なり数\",len(c))#重複しない要素（一意な要素）の個数（種類）をカウント\n",
    "print(\"総数\",len(list))#リストのサイズの取得(len関数)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#^\t行の先頭\t^abc\tabcdef\n",
    "#.\t任意の一文字\ta.c\tabc, acc, aac\n",
    "#+\t1回以上の繰り返し\tab+\tab, abb, abbb\n",
    "#?\t0回または1回\tab?\ta, ab\n",
    "#[★]\t★のどれか1文字\t[a-c]\ta, b, c\n",
    "#\\s\t任意の空白文字\n",
    "#\\S\t任意の空白文字以外\n",
    "#空白に応じてテキストを消す？\n",
    "#ーーーに応じてテキスト消す？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(///) as f\n",
    "で勝手にclosed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analize():\n",
    "    result =\n",
    "    for line in result[:-2]:#ー２までは処理しない\n",
    "        word,d=\n",
    "        split(\",\")[0] [a a.a.///]の二番目のaで分ける\n",
    "        word list.append((word,d))\n",
    "    return    \n",
    "        \n",
    "analize(test)        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-8-e11f5abcdf49>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-e11f5abcdf49>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    print(l)\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "\n",
    "    # ヘッダ部分の削除\n",
    "    line = re.sub(u'-----[\\s\\S]*-----', '', line)\n",
    "    # フッタ部分の削除\n",
    "    line = re.split(u'底本：',line)[0]\n",
    "    \n",
    "#data= open(\"bbc.txt\", \"r\")#ファイルを開く\n",
    "    #print(words)\n",
    "    #print(l)\n",
    "    #print(list)\n",
    "#print(\"総数\",len(list))\n",
    "#words = words.rstrip('\\n')\n",
    "#for line in open('carmen.txt', 'r',encoding=\"utf-8_sig\" ):\n",
    "#print(l)\n",
    "\n",
    "# print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeCab\tMeCab\tMeCab\t名詞-一般\t\t\n",
      "を\tヲ\tを\t助詞-格助詞-一般\t\t\n",
      "用い\tモチイ\t用いる\t動詞-自立\t一段\t連用形\n",
      "て\tテ\tて\t助詞-接続助詞\t\t\n",
      "文章\tブンショウ\t文章\t名詞-一般\t\t\n",
      "を\tヲ\tを\t助詞-格助詞-一般\t\t\n",
      "分割\tブンカツ\t分割\t名詞-サ変接続\t\t\n",
      "し\tシ\tする\t動詞-自立\tサ変・スル\t連用形\n",
      "て\tテ\tて\t助詞-接続助詞\t\t\n",
      "み\tミ\tみる\t動詞-非自立\t一段\t連用形\n",
      "ます\tマス\tます\t助動詞\t特殊・マス\t基本形\n",
      "。\t。\t。\t記号-句点\t\t\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    " \n",
    "mecab = MeCab.Tagger (\"-Ochasen\")\n",
    "print(mecab.parse(\"MeCabを用いて文章を分割してみます。\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unicode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fe947df7c78d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# SJISコードの文字列をunicode内部表現形式に変換\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtxt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SJIS'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# 置換用の関数のimport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unicode' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "f = open('carmen.txt')\n",
    "txt = f.read()\n",
    "f.close()\n",
    "\n",
    "# 前処理開始\n",
    "\n",
    "# SJISコードの文字列をunicode内部表現形式に変換\n",
    "txt2 = unicode( txt, encoding='SJIS')\n",
    "\n",
    "# 置換用の関数のimport\n",
    "import re\n",
    "\n",
    "# ルビなどの削除\n",
    "txt2 = re.sub(u'《[^》]+》', '', txt2)\n",
    "txt2 = re.sub(u'｜', '', txt2)\n",
    "txt2 = re.sub(u'［.+?］', '', txt2)\n",
    "\n",
    "# ヘッダ部分の削除\n",
    "txt2 = re.sub(u'-----[\\s\\S]*-----', '', txt2)\n",
    "\n",
    "# フッタ部分の削除\n",
    "txt2 = re.split(u'底本：',txt2)[0]\n",
    "\n",
    "# 改行の削除\n",
    "txt2 = re.sub(u'\\n', '', txt2)\n",
    "txt2 = re.sub(u'\\r', '', txt2)\n",
    "\n",
    "# janomeを使った名詞リストの作成\n",
    "word_list = []\n",
    "from janome.tokenizer import Tokenizer\n",
    "t = Tokenizer()\n",
    "for token in t.tokenize(txt2, stream=True):\n",
    "    partOfSpeech = token.part_of_speech.split(',')[0]\n",
    "    if partOfSpeech == u'名詞':\n",
    "        word_list.append(token.surface)\n",
    "print ('====')\n",
    "print (word_list[0])\n",
    "print (word_list[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
