{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import collections\n",
    "import sys\n",
    "import MeCab\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # carmen # akai_heya# meijinden # at_a_railway_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " corpus = ['This is the first document.','This document is the second document.','And this is the third one.','Is this the first document?',]\n",
    " vectorizer = CountVectorizer()\n",
    " matrix = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n"
     ]
    }
   ],
   "source": [
    " print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagger = MeCab.Tagger('-Owakati')    # 品詞情報が不要の場合\n",
    "def tokenize(text):\n",
    "    token_list = tagger.parse(text).split()\n",
    "    return token_list\n",
    "\n",
    "corpus = ['これは最初の文書です。','この文書は２番目の文書です。','そしてこれは3番目のものです。','これは最初の文書ですか？',]\n",
    "vectorizer = CountVectorizer(analyzer=tokenize)\n",
    "matrix = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3', '。', 'か', 'この', 'これ', 'そして', 'です', 'の', 'は', 'もの', '文書', '最初', '番目', '２', '？']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 1 0 1 1 1 0 1 1 0 0 0]\n",
      " [0 1 0 1 0 0 1 1 1 0 2 0 1 1 0]\n",
      " [1 1 0 0 1 1 1 1 1 1 0 0 1 0 0]\n",
      " [0 0 1 0 1 0 1 1 1 0 1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.    0.39  0.    0.    0.39  0.    0.32  0.32  0.32  0.    0.39  0.48\n",
      "   0.    0.    0.  ]\n",
      " [ 0.    0.27  0.    0.43  0.    0.    0.22  0.22  0.22  0.    0.55  0.\n",
      "   0.34  0.43  0.  ]\n",
      " [ 0.44  0.28  0.    0.    0.28  0.44  0.23  0.23  0.23  0.44  0.    0.\n",
      "   0.34  0.    0.  ]\n",
      " [ 0.    0.    0.48  0.    0.31  0.    0.25  0.25  0.25  0.    0.31  0.38\n",
      "   0.    0.    0.48]]\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "tfidf_matrix = tfidf.fit_transform(matrix)\n",
    "np.set_printoptions(precision=2) \n",
    "print(tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_list = np.array(vectorizer.get_feature_names())\n",
    "population = np.array(matrix.toarray())\n",
    "indices = np.argsort(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['3' '。' 'この' 'そして' 'もの' '番目' '２' 'か' 'これ' 'です' 'の' 'は' '文書' '最初' '？']\n",
      " ['か' 'この' '文書' '最初' '２' '？' '3' '。' 'これ' 'そして' 'です' 'の' 'は' 'もの' '番目']\n",
      " ['3' 'か' 'これ' 'そして' 'もの' '最初' '？' '。' 'この' 'です' 'の' 'は' '番目' '２' '文書']\n",
      " ['3' 'か' 'この' 'そして' 'もの' '番目' '２' '？' '。' 'これ' 'です' 'の' 'は' '文書' '最初']]\n",
      "[['3' '。' 'この' 'そして' 'もの' '番目' '２' 'か' 'これ']\n",
      " ['か' 'この' '文書' '最初' '２' '？' '3' '。' 'これ']\n",
      " ['3' 'か' 'これ' 'そして' 'もの' '最初' '？' '。' 'この']\n",
      " ['3' 'か' 'この' 'そして' 'もの' '番目' '２' '？' '。']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(name_list[indices[::-1]])\n",
    "print(name_list[indices[::-1,0:9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['3' 'か' 'この' 'そして' 'もの' '番目' '２' '？' '。' 'これ' 'です' 'の' 'は' '文書' '最初']\n",
      " ['3' 'か' 'これ' 'そして' 'もの' '最初' '？' '。' 'この' 'です' 'の' 'は' '番目' '２' '文書']\n",
      " ['か' 'この' '文書' '最初' '２' '？' '3' '。' 'これ' 'そして' 'です' 'の' 'は' 'もの' '番目']\n",
      " ['3' '。' 'この' 'そして' 'もの' '番目' '２' 'か' 'これ' 'です' 'の' 'は' '文書' '最初' '？']] 5\n"
     ]
    }
   ],
   "source": [
    " print(name_list[indices])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  2  3  5  9 12 13 14  1  4  6  7  8 10 11]\n",
      " [ 0  2  4  5  9 11 14  1  3  6  7  8 12 13 10]\n",
      " [ 2  3 10 11 13 14  0  1  4  5  6  7  8  9 12]\n",
      " [ 0  1  3  5  9 12 13  2  4  6  7  8 10 11 14]]\n"
     ]
    }
   ],
   "source": [
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
