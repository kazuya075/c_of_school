{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import collections\n",
    "import sys\n",
    "import MeCab\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各単語の出現回数 [('いる', 21), ('僕', 18), ('する', 18), ('の', 15), ('イイナ', 13), ('人', 13), ('君', 10), ('カルメン', 10), ('等', 8), ('それ', 7), ('見る', 7), ('晩', 6), ('云う', 6), ('言う', 5), ('革命', 4), ('前', 4), ('ダンチェンコ', 4), ('舞台', 4), ('話す', 4), ('露西亜', 4)]\n",
      "単語の異なり数 272\n",
      "総数 509\n"
     ]
    }
   ],
   "source": [
    "\n",
    "textdata= open('carmen.txt', 'r').read()\n",
    "\n",
    "# 青空文庫のための固有処理\n",
    "textdata = re.split('\\-{5,}', textdata)[2]\n",
    "\n",
    "textdata = re.split('底本：', textdata)[0]\n",
    "textdata = textdata.strip()\n",
    "\n",
    "mecab = MeCab.Tagger()\n",
    "results = []\n",
    "lines = textdata.split(\"\\r\\n\")\n",
    "for line in lines:\n",
    "    r = []\n",
    "    # 学習に使わない表現の削除処理\n",
    "    s = line\n",
    "    s = s.replace(\"｜\", \"\")\n",
    "    s = s.replace('\\u3000', '')\n",
    "    s = re.sub(r'《.+?》', \"\", s)\n",
    "    s = re.sub(r'［.+?］', '', s)\n",
    "    # Mecab\n",
    "    node = mecab.parseToNode(s)\n",
    "    while node:\n",
    "        # 単語を取得\n",
    "        if node.feature.split(\",\")[6] == '*':\n",
    "            word = node.surface\n",
    "        else:\n",
    "            word = node.feature.split(\",\")[6]\n",
    "\n",
    "        # 品詞を取得\n",
    "        part = node.feature.split(\",\")[0]\n",
    "\n",
    "        if part in [\"名詞\", \"形容詞\", \"動詞\"]:#, \"記号\"\n",
    "            r.append(word)\n",
    "            \n",
    "        node = node.next\n",
    "    rl = (\" \".join(r)).strip()\n",
    "    results.append(rl)\n",
    "\n",
    "#print(results)\n",
    "c = collections.Counter(r)#単語の出現個数をカウント\n",
    "print(\"各単語の出現回数\",c.most_common(20))#表示 most_common()メソッドに引数nを指定すると、出現回数の多いn要素のみを返す。\n",
    "print(\"単語の異なり数\",len(c))#重複しない要素（一意な要素）の個数（種類）をカウント\n",
    "print(\"総数\",len(r))#リストのサイズの取得(len関数)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['カルメン', '芥川', '龍之介', '革命', '前', '革命', '後', 'あれ', '革命', '前', '革命', '前', '言え', '僕', '当時', '小耳', '挟ん', 'ダンチェンコ', '洒落', '覚え', 'いる', '蒸し暑い', '雨', 'よい', '夜', '舞台', '監督', '君', '帝劇', '露台', '佇み', '炭酸', '水', 'コップ', '片手', '詩人', 'ダンチェンコ', '話し', 'い', '亜麻', '色', '髪の毛', 'し', '盲目', '詩人', 'ダンチェンコ', 'これ', '時勢', '露西亜', 'グランド', 'オペラ', '日本', '東京', 'やって来る', '言う', 'の', 'それ', 'ボルシェヴィッキ', 'カゲキ', '派', '問答', 'あっ', 'の', '確か', '初日', '五', '日', '目', '晩', 'カルメン', '舞台', '登っ', '晩', '僕', 'カルメン', '扮する', 'はず', 'イイナ・ブルスカアヤ', '夢中', 'なっ', 'い', 'イイナ', '目', '大きい', '小鼻', '張っ', '肉感', '強い', '女', '僕', 'カルメン', '扮する', 'イイナ', '観る', 'こと', '楽しみ', 'し', 'い', '一幕', '上っ', 'の', '見る', 'カルメン', '扮', 'し', 'の', 'イイ', '水色', '目', 'し', '鼻', '高い', '云う', '貧相', '女優', '僕', '君', 'ボックス', 'タキシイド', '胸', '並べ', '落胆', 'し', '訣', '行か', 'カルメン', '僕', '等', 'イイナ', 'イイナ', '今夜', '休み', 'そう', '原因', 'ロマンティック', 'し', 'ん', '云う', '帝国', '侯爵', '一', '人', 'イイナ', 'あと', '追っかけ', '来', 'おととい', '東京', '着い', 'ん', 'そう', 'イイナ', '亜米利加', '人', '商人', '世話', 'なっ', 'いる', 'そいつ', '見', '侯爵', '絶望', 'し', 'ん', 'ゆうべ', 'ホテル', '自分', '部屋', '首', '縊', '死ん', 'じまっ', 'ん', 'そう', '僕', '話', '聞い', 'いる', 'うち', '場景', '思い出し', 'それ', '夜', '更け', 'ホテル', '一室', '大勢', '男女', '囲ま', 'れ', 'まま', 'トランプ', '弄ん', 'いる', 'イイナ', '黒', '赤', '着物', '着', 'イイ', 'ジプシイ', '占い', 'し', 'いる', '見え', '君', 'ほほ笑みかけ', '今度', 'あなた', '運', '見', '上げ', '言っ', '言っ', 'の', '云う', 'こと', 'ダア', '以外', '露西亜', '語', '知ら', '僕', '十', '二', '箇国', '言葉', '通じ', '君', '翻訳', 'し', '貰う', 'ほか', 'それ', 'トランプ', 'まくっ', '見', '後', 'あなた', '人', '幸福', 'あなた', '愛する', '人', '結婚', '出来', '言っ', '人', '云う', 'の', 'イイ', '側', '誰', '話し', 'い', '露西亜', '人', '僕', '不幸', '人', '顔', '服装', 'の', '覚え', 'い', '僕', '覚え', 'いる', 'の', '胸', '挿し', 'い', '石竹', 'イイナ', '愛', '失っ', 'ため', '首', '縊', '死ん', '云う', 'の', '晩', '人', 'なかっ', 'それ', '今夜', '出', 'はず', '好い加減', '外', '出', 'やる', '君', 'イイ', '党', '一幕', '見', '行こ', '僕', '等', 'ダンチェンコ', '話し', 'し', 'の', '幕', '合い', 'の', '次', '幕', '僕', '等', '退屈', '僕', '等', '席', '五', '分', 'たた', 'うち', '外国', '人', '五', '六', '人', '僕', '等', '正面', '当る', '向う側', 'ボックス', 'はいっ', '来', '彼等', '先', '立っ', 'の', '紛れ', 'ない', 'イイナ・ブルスカアヤ', 'イイナ', 'ボックス', '一番', '前', '坐り', '孔雀', '羽根', '扇', '使い', '舞台', '眺め', '出し', 'なら', '同伴', '外国', '人', '男女', '中', '彼女', '檀那', '亜米利加', '人', '交っ', 'い', 'の', '愉快', 'そう', '笑っ', '話し', 'し', '出し', 'イイナ', 'イイナ', '僕', '等', '最後', '幕', 'カルメン', '死骸', '擁し', 'ホセ', 'カルメン', 'カルメン', '慟哭', 'する', '僕', '等', 'ボックス', '離れ', 'それ', '舞台', 'イイナ・ブルスカアヤ', '見', 'い', 'ため', '男', '殺し', 'こと', '思っ', 'い', '露西亜', 'カルメン', '見', 'い', 'ため', 'それ', '二', '三', '日', 'たっ', '晩', '僕', 'ある', 'レストラン', '隅', '君', 'テエブル', '囲ん', 'い', '君', 'イイナ', '晩', '以来', '確か', '左', '薬指', '繃帯', 'し', 'い', '気', 'つい', 'いる', '云え', '繃帯', 'し', 'い', 'よう', 'イイナ', '晩', 'ホテル', '帰る', '駄目', '君', 'それ', '飲ん', '僕', '君', '注意', 'し', '薄い', '光', 'さし', 'グラス', '中', '小さい', '黄金虫', '一', '匹', '仰向け', 'なっ', 'もがい', 'い', '君', '白', '葡萄', '酒', '床', 'こぼし', '妙', '顔', 'し', 'つけ加え', '皿', '壁', '叩きつけ', '欠片', 'カスタネット', '代り', 'し', '指', '血', '出る', 'の', 'かまわ', 'カルメン', 'よう', '踊っ', 'の', 'そこ', '僕', '等', '興奮', 'つり合わ', '顔', 'し', '頭', '白い', '給仕', '一', '人', '静', '鮭', '皿', '運ん', '来', '大正', '十', '五', '年', '四月', '十', '日']\n",
      "各単語の出現回数 [('僕', 18), ('し', 17), ('の', 15), ('い', 14), ('イイナ', 13), ('人', 13), ('カルメン', 11), ('君', 10), ('等', 8), ('いる', 7), ('それ', 7), ('晩', 6), ('見', 6), ('云う', 5), ('革命', 4), ('前', 4), ('ダンチェンコ', 4), ('舞台', 4), ('話し', 4), ('露西亜', 4)]\n",
      "単語の異なり数 287\n",
      "総数 512\n"
     ]
    }
   ],
   "source": [
    "data= open('carmen.txt', 'r')\n",
    "textdata=data.read()\n",
    "textdata = re.split('\\-{5,}', textdata)[0]+ re.split('\\-{5,}', textdata)[2]\n",
    "textdata = re.split('底本：', textdata)[0]\n",
    "textdata = textdata.strip()#stripメソッドで改行コードを取り除く\n",
    "\n",
    "#print(textdata)\n",
    "mecab = MeCab.Tagger()\n",
    "results = []\n",
    "lines = textdata.split(\"\\r\\n\")\n",
    "for line in lines:\n",
    "    r = []\n",
    "    # 学習に使わない表現の削除処理\n",
    "    s = line\n",
    "    s = s.replace(\"｜\", \"\")\n",
    "    s = s.replace('\\u3000', '')\n",
    "    s = re.sub(r'《.+?》', \"\", s)\n",
    "    s = re.sub(r'［.+?］', '', s)\n",
    "    # Mecab\n",
    "    node = mecab.parseToNode(s)#parseToNode()を使うと形態素の詳細情報\n",
    "    while node:\n",
    "        # 単語を取得\n",
    "        word = node.surface#surfaceで表層形\n",
    "        # 品詞を取得\n",
    "        part = node.feature.split(\",\")[0]#featureで形態素情報\n",
    "\n",
    "        if part in [\"名詞\", \"形容詞\", \"動詞\"]:#, \"記号\"\n",
    "             r.append(word)#words.split()\n",
    "            \n",
    "        node = node.next\n",
    "    \n",
    "#print(r)\n",
    "c = collections.Counter(r)#単語の出現個数をカウント\n",
    "print(\"各単語の出現回数\",c.most_common(20))#表示 most_common()メソッドに引数nを指定すると、出現回数の多いn要素のみを返す。\n",
    "print(\"単語の異なり数\",len(c))#重複しない要素（一意な要素）の個数（種類）をカウント\n",
    "print(\"総数\",len(r))#リストのサイズの取得(len関数)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "停車場にて\n",
      "AT A RAILWAY STATION\n",
      "小泉八雲　Lafcadio Hearn\n",
      "林田清明訳\n",
      "\n",
      "\n",
      "\n",
      "［＃地付き］明治二六年六月七日\n",
      "\n",
      "　きのうの福岡発信の電報によると、当地で逮捕された兇徒が、裁判のために、きょう正午着の汽車で熊本へ護送されるということだった。熊本の警察官が、この兇徒を引取るために福岡に出張していたのである。\n",
      "　四年前、熊本市｜相撲町《すもうちょう》のある家に、夜半、盗人が押し入り、家人らを脅して、縛り上げ、高価な財産を盗んだ。警察がうまく追跡して、盗人は二四時間以内に逮捕されたので盗品を処分することもできなかった。ところが、警察署に連行されるとき、捕縄《とりなわ》を解《ほど》き、サーベルを奪い、巡査を殺害して逃走したのである。つい先週までこの兇徒の行方はまるっきりつかめなかった。\n",
      "　ところが、たまたま福岡の監獄所を訪れていた熊本の刑事が、四年もの間、写真のように脳裏に焼き付けていた顔を、囚人たちの中に見つけたのである。\n",
      "　「あの男は？」獄吏に尋ねた。\n",
      "　「窃盗犯でありますが、ここでは草部と記録されております。」\n",
      "　刑事は囚人のところに歩み寄ると、言った、\n",
      "　「お前の名前は草部ではないな。熊本の殺人容疑でお尋ね者の、野村禎一だ。」\n",
      "　重罪犯人はすっかり白状したのである。\n",
      "\n",
      "　停車場に到着するのを見届けようと私も出かけたが、かなりの人が詰めかけている。人々が憤るのをたぶん見聞きするだろうと思っていたし、一悶着《ひともんちゃく》起こりはしないかとすら恐れてもいた。殺された巡査は周囲《まわり》からとても好かれていたし、彼の身内の者も、おそらくこの見物人たちの中にいるはずである。熊本の群集もとても温和《おとな》しいとはいえないのである。それで警備のために多数の警官が配置されているものとばかり思っていたが、私の予想は外れた。\n",
      "　汽車は、下駄を履いた乗客たちのあわてた急ぎ足やカラコロという音が響き、また新聞やラムネなど飲み物を売る少年たちの呼び声などで、いつものようにあわただしく、また騒々しい光景の中に停車した。改札口の外で、私たちは五分近くも待っていた。そのとき、警部が改札口の扉を押し開けて出てきて、犯人が現れる――大柄の粗野な感じの男で、顔は俯《うつむ》き加減にしており、両の手は背中で縛られている。犯人と護送の巡査は二人とも改札口の前で、立ち止まった。そして、詰めかけている人たちが黙って一目見ようと前の方に押し寄せた。そのとき、警部が叫んだ。\n",
      "　「杉原さん！　杉原おきびさん！　いませんか？」\n",
      "　「はい！」と声がすると、私の近くに立っていた、子どもを背負った細身の小柄な婦人が人混みをかき分けて進み出た。この人は殺された巡査の妻で、背負っているのが息子である。警部が手を前後に振るしぐさをすると、群衆は後ろずさりに下がった。そうして、犯人と護衛の警官のためのスペースが出来た。この空間で子どもを背負った未亡人と殺人者とが向き合って立つことになった。あたりは静まり返っている。\n",
      "　そして、警部がこの未亡人にではなく、子どもに話しかけた。低い声だが、はっきりと喋ったので、一言一言が明瞭に聞き取れた。\n",
      "　「坊や、この男が四年前にあんたのお父《とつ》さんを殺したんだよ。あんたはまだ生まれちゃいなくて、お母《つか》さんのお腹の中にいたんだからなぁ。あんたを可愛がってくれるはずのお父《とつ》さんがいないのは、この男の仕業だよ。見てご覧――ここで警部は犯人の顎に手をやり、しっかりと彼の目を向けるようにした――坊や、よく見てご覧、こいつを！　怖がらなくていいから。辛いだろうが、そうしなくちゃいけない。あの男を見るんだ！」\n",
      "　母親の肩越しに、坊やは怖がってでもいるかのように、眼を見開いて見つめる。そして、今度はしゃくり泣き始め、涙が溢れてくる。坊やは、しっかりと、また言われたように男をじっと見つめている。まっすぐにその卑屈な顔をずっと覗き込んでいた。\n",
      "　周りの人たちも息を呑んだようである。\n",
      "　犯人の表情がゆがむのが見えた。後ろ手に縛られているにもかかわらず、彼は膝の上に崩れ落ち、顔を土埃《ほこり》の中に打ちつけて、人の心を震わせるような、しゃがれた声で自責の念に駆られて、しばらく嗚咽《おえつ》していた。\n",
      "　「済まない！　許してくれ！　坊や、堪忍しておくれ！　憎んでいたからじゃねぇんだ。怖かったばかりに、ただ逃げようと思ってやっちまったんだ。俺がなにもかも悪いんだ。あんたに、まったく取り返しの付かない、悪いことをしちまった！　罪を償わなくちゃならねぇ。死にてぇだ。そう喜んで死にますとも！　ですから、坊や、お情けと思って、俺を許しておくんなせぇ！」\n",
      "　男の子は静かにまだしゃくり泣いている。警部は肩を震わせている犯人の男を引き起こした。黙りこくったままだった人々は、左右に分かれて道を空《あ》けた。するとそのとき、まったく突然に、群衆がみなすすり泣き始めたのである。銅像のような表情をした護送の警官がそばを通りすぎるとき、私は以前にも見たことのないもの――ほとんどの人もかつて見たことのない――そして私もおそらく再び見ることのないであろう――日本の警官の涙を目撃したのである。\n",
      "\n",
      "　人だかりも潮《しお》が引くように少なくなった。私は取り残され、この場の不思議な教訓について考えている。ここには、自分が犯した犯罪行為のために遺児となり、未亡人となったという明白な結末を目の当たりにして、心情的に犯罪の意味について悟らせるという、本来そうあるべきだが、温情ある裁きがあったのである。ここには、死を前にしてひたすら赦《ゆる》しを乞う、一途な後悔の念があった。また、ここには、怒りだせばこの国の中では最も危険な庶民がいた――ところが、この人たちは、人生の困難さや人間の弱さを純朴に、また身にしみて経験しているので、激しい怒りではなく、罪についての大きな悲しみだけで胸塞がれ、後悔の念と恥を知ることで満足しており、またあらゆることに感動し、何もかもを分かっているのであった。\n",
      "\n",
      "　このエピソードのもっとも重要な事実は、それがきわめて東洋的であるからだが、つぎのことにある。犯人を悔い改めさせたのは、彼自身も持っている、子に対する父親の心情に訴えたからであった――子どもたちへの深い愛情こそが、あらゆる日本人の心の大きな部分を占めているのである。\n",
      "\n",
      "　日本では最もよく知られた盗賊の石川五右衛門に、つぎの話がある。ある夜、殺して、盗みを働こうと人家に忍び込んだときに、自分に両手を差し伸べている赤ん坊の微笑みに、五右衛門はすっかり気を奪われた。そして、この無邪気な幼子と遊んでいるうちに、自分の所期の目的を達成する機会を失ったというのである。\n",
      "　これは信じられない話ではない。警察の記録には、毎年、プロの犯罪人たちが子どもらに示した同情の報告がある。地方新聞に載った、数ヶ月前の凄惨な大量殺人事件は、強盗が睡眠中の一家七人を文字通りに切り刻んだものであった。警察は、一面の血の海の中でひとり泣いている小さな男の子を発見したが、まったくの無傷であった。警察によれば、犯人らが子どもを傷つけまいとしてかなり用心した確かな証拠があるという。\n",
      "\n",
      "\n",
      "\n",
      "翻訳の\n",
      "['停車場', 'AT', 'A', 'RAILWAY', 'STATION', '小泉', '八雲', 'Lafcadio', 'Hearn', '林田', '清明', '訳', '明治', '二', '六', '年', '六月', '七', '日', 'きのう', '福岡', '発信', '電報', 'よる', '当地', '逮捕', 'さ', 'れ', '兇徒', '裁判', 'ため', 'きょう', '正午', '着', '汽車', '熊本', '護送', 'さ', 'れる', 'こと', '熊本', '警察官', '兇徒', '引', '取る', 'ため', '福岡', '出張', 'し', 'い', 'の', '四', '年', '前', '熊本', '市', '相撲', '町', 'ある', '家', '夜半', '盗人', '押し入り', '家人', 'ら', '脅し', '縛り上げ', '高価', '財産', '盗ん', '警察', 'うまく', '追跡', 'し', '盗人', '二', '四', '時間', '以内', '逮捕', 'さ', 'れ', '盗品', '処分', 'する', 'こと', 'でき', '警察', '署', '連行', 'さ', 'れる', 'とき', '捕縄', '解き', 'サーベル', '奪い', '巡査', '殺害', 'し', '逃走', 'し', 'の', '先週', '兇徒', '行方', 'つかめ', '福岡', '監獄', '所', '訪れ', 'い', '熊本', '刑事', '四', '年', 'もの', '間', '写真', 'よう', '脳裏', '焼き付け', 'い', '顔', '囚人', 'たち', '中', '見つけ', 'の', '男', '獄吏', '尋ね', '窃盗', '犯', 'ここ', '草部', '記録', 'さ', 'れ', 'おり', '刑事', '囚人', 'ところ', '歩み寄る', '言っ', 'お前', '名前', '草部', 'ない', '熊本', '殺人', '容疑', 'お尋ね者', '野村', '禎一', '重罪', '犯人', '白状', 'し', 'の', '停車場', '到着', 'する', 'の', '見届けよ', '私', '出かけ', 'かなり', '人', '詰めかけ', 'いる', '人々', '憤る', 'の', '見聞き', 'する', '思っ', 'い', '一', '悶着', '起こり', 'し', '恐れ', 'い', '殺さ', 'れ', '巡査', '周囲', '好か', 'れ', 'い', '彼', '身内', '者', '見物人', 'たち', '中', 'いる', 'はず', '熊本', '群集', '温和', 'しい', 'いえ', 'の', 'それ', '警備', 'ため', '多数', '警官', '配置', 'さ', 'れ', 'いる', 'もの', '思っ', 'い', '私', '予想', '外れ', '汽車', '下駄', '履い', '乗客', 'たち', 'あわて', '急ぎ足', 'カラコロ', '音', '響き', '新聞', 'ラムネ', '飲み物', '売る', '少年', 'たち', '呼び声', 'よう', 'あわただしく', '騒々しい', '光景', '中', '停車', 'し', '改札', '口', '外', '私', 'たち', '五', '分', '近く', '待っ', 'い', 'とき', '警部', '改札', '口', '扉', '押し', '開け', '出', 'き', '犯人', '現れる', '大柄', '粗野', '感じ', '男', '顔', '俯き', '加減', 'し', 'おり', '両', '手', '背中', '縛ら', 'れ', 'いる', '犯人', '護送', '巡査', '二', '人', '改札', '口', '前', '立ち止まっ', '詰めかけ', 'いる', '人', 'たち', '黙っ', '見よ', '前', '方', '押し寄せ', 'とき', '警部', '叫ん', '杉原', 'さん', '杉原', 'おき', 'びさん', 'い', '声', 'する', '私', '近く', '立っ', 'い', '子ども', '背負っ', '細身', '小柄', '婦人', '人混み', 'かき分け', '進み出', '人', '殺さ', 'れ', '巡査', '妻', '背負っ', 'いる', 'の', '息子', '警部', '手', '前後', '振る', 'しぐさ', 'する', '群衆', '後ろ', 'さり', '下がっ', '犯人', '護衛', '警官', 'ため', 'スペース', '出来', '空間', '子ども', '背負っ', '未亡人', '殺人', '者', '向き合っ', '立つ', 'こと', 'なっ', 'あたり', '静まり返っ', 'いる', '警部', '未亡人', '子ども', '話しかけ', '低い', '声', '喋っ', '一言', '一言', '明瞭', '聞き取れ', '坊や', '男', '四', '年', '前', 'あんた', 'お父さん', '殺し', 'ん', 'あんた', '生まれ', 'い', 'お母さん', '腹の中', 'いたん', 'あんた', '可愛がっ', 'くれる', 'はず', 'お父さん', 'い', 'の', '男', '仕業', '見', 'ご覧', 'ここ', '警部', '犯人', '顎', '手', 'やり', '彼', '目', '向ける', 'よう', 'し', '坊や', '見', 'ご覧', 'こいつ', '怖がら', 'いい', '辛い', 'し', 'いけ', '男', '見る', 'ん', '母親', '肩越し', '坊や', '怖がっ', 'いる', 'よう', '眼', '見開い', '見つめる', '今度', 'しゃくり泣き', '始め', '涙', '溢れ', 'くる', '坊や', '言わ', 'れ', 'よう', '男', '見つめ', 'いる', '卑屈', '顔', '覗き', '込ん', 'い', '周り', '人', 'たち', '息', '呑ん', 'よう', '犯人', '表情', 'ゆがむ', 'の', '見え', '後ろ手', '縛ら', 'れ', 'いる', 'かかわら', '彼', '膝', '上', '崩れ落ち', '顔', '土埃', '中', '打ちつけ', '人', '心', '震わせる', 'よう', 'しゃがれ', '声', '自責', '念', '駆ら', 'れ', '嗚咽', 'し', 'い', '済まない', '許し', 'くれ', '坊や', '堪忍', 'し', 'おくれ', '憎ん', 'い', 'ん', '怖かっ', '逃げよ', '思っ', 'やっ', 'ちまっ', 'ん', '俺', '悪い', 'ん', 'あんた', '取り返し', '付か', '悪い', 'こと', 'し', 'ちまっ', '罪', '償わ', '死に', '喜ん', '死に', '坊や', '情け', '思っ', '俺', '許し', 'おく', 'ん', 'なせ', 'ぇ', '男の子', '静か', 'しゃくり', '泣い', 'いる', '警部', '肩', '震わせ', 'いる', '犯人', '男', '引き起こし', '黙りこくっ', 'まま', '人々', '左右', '分かれ', '道', '空け', 'とき', '群衆', 'みな', 'すすり泣き', '始め', 'の', '銅像', 'よう', '表情', 'し', '護送', '警官', 'そば', '通り', 'すぎる', 'とき', '私', '以前', '見', 'こと', 'ない', 'もの', '人', '見', 'こと', 'ない', '私', '見る', 'こと', 'ない', '日本', '警官', '涙', '目撃', 'し', 'の', '人だかり', '潮', '引く', 'よう', '少なく', 'なっ', '私', '取り残さ', 'れ', '場', '不思議', '教訓', '考え', 'いる', 'ここ', '自分', '犯し', '犯罪', '行為', 'ため', '遺児', 'なり', '未亡人', 'なっ', '明白', '結末', 'し', '心情', '的', '犯罪', '意味', '悟ら', 'せる', '本来', 'ある', '温情', 'ある', '裁き', 'あっ', 'の', 'ここ', '死', '前', 'し', '赦し', '乞う', '一途', '後悔', '念', 'あっ', 'ここ', '怒り', 'だせ', '国', '中', '危険', '庶民', 'い', '人', 'たち', '人生', '困難', 'さ', '人間', '弱', 'さ', '純朴', '身', 'しみ', '経験', 'し', 'いる', '激しい', '怒り', '罪', '悲しみ', '胸', '塞が', 'れ', '後悔', '念', '恥', '知る', 'こと', '満足', 'し', 'おり', 'こと', '感動', 'し', '何もかも', '分かっ', 'いる', 'の', 'エピソード', '重要', '事実', 'それ', '東洋', '的', 'つぎ', 'こと', 'ある', '犯人', '悔い改め', 'させ', 'の', '彼', '自身', '持っ', 'いる', '子', '父親', '心情', '訴え', '子ども', 'たち', '深い', '愛情', '日本人', '心', '部分', '占め', 'いる', 'の', '日本', '知ら', 'れ', '盗賊', '石川', '五右衛門', 'つぎ', '話', 'ある', '夜', '殺し', '盗み', '働こ', '人家', '忍び込ん', 'とき', '自分', '両手', '差し伸べ', 'いる', '赤ん坊', '微笑み', '五右衛門', '気', '奪わ', 'れ', '無邪気', '幼子', '遊ん', 'いる', 'うち', '自分', '所期', '目的', '達成', 'する', '機会', '失っ', 'の', 'これ', '信じ', 'られ', '話', '警察', '記録', '毎年', 'プロ', '犯罪', '人', 'たち', '子ども', 'ら', '示し', '同情', '報告', 'ある', '地方', '新聞', '載っ', '数', 'ヶ月', '前', '凄惨', '大量', '殺人', '事件', '強盗', '睡眠', '中', '一家', '七', '人', '文字通り', '切り刻ん', 'もの', '警察', '一', '面', '血', '海', '中', '泣い', 'いる', '男の子', '発見', 'し', '無傷', '警察', 'よれ', '犯人', 'ら', '子ども', '傷つけ', '用心', 'し', '確か', '証拠', 'ある', 'いう', '翻訳']\n",
      "各単語の出現回数 [('し', 22), ('いる', 20), ('の', 17), ('い', 16), ('れ', 15), ('こと', 10), ('たち', 10), ('人', 10), ('よう', 9), ('犯人', 9), ('さ', 8), ('ある', 7), ('中', 7), ('男', 7), ('私', 7), ('熊本', 6), ('前', 6), ('する', 6), ('とき', 6), ('警部', 6)]\n",
      "単語の異なり数 477\n",
      "総数 803\n"
     ]
    }
   ],
   "source": [
    "data= open('at_a_railway_station.txt', 'r')\n",
    "textdata=data.read()\n",
    "textdata =re.split('\\-{5,}', textdata)[0]+ re.split('\\-{5,}', textdata)[2]\n",
    "textdata = re.split('底本：', textdata)[0]\n",
    "textdata = textdata.strip()#stripメソッドで改行コードを取り除く\n",
    "\n",
    "print(textdata)\n",
    "mecab = MeCab.Tagger()\n",
    "results = []\n",
    "lines = textdata.split(\"\\r\\n\")\n",
    "for line in lines:\n",
    "    r = []\n",
    "    # 学習に使わない表現の削除処理\n",
    "    s = line\n",
    "    s = s.replace(\"｜\", \"\")\n",
    "    s = s.replace('\\u3000', '')\n",
    "    s = re.sub(r'《.+?》', \"\", s)\n",
    "    s = re.sub(r'［.+?］', '', s)\n",
    "    # Mecab\n",
    "    node = mecab.parseToNode(s)#parseToNode()を使うと形態素の詳細情報\n",
    "    while node:\n",
    "        # 単語を取得\n",
    "        word = node.surface#surfaceで表層形\n",
    "        # 品詞を取得\n",
    "        part = node.feature.split(\",\")[0]#featureで形態素情報\n",
    "\n",
    "        if part in [\"名詞\", \"形容詞\", \"動詞\"]:#, \"記号\"\n",
    "             r.append(word)#words.split()\n",
    "            \n",
    "        node = node.next\n",
    "    \n",
    "print(r)\n",
    "c = collections.Counter(r)#単語の出現個数をカウント\n",
    "print(\"各単語の出現回数\",c.most_common(20))#表示 most_common()メソッドに引数nを指定すると、出現回数の多いn要素のみを返す。\n",
    "print(\"単語の異なり数\",len(c))#重複しない要素（一意な要素）の個数（種類）をカウント\n",
    "print(\"総数\",len(r))#リストのサイズの取得(len関数)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各単語の出現回数 [('の', 105), ('し', 104), ('こと', 103), ('私', 84), ('よう', 70), ('いる', 69), ('れ', 50), ('い', 42), ('さ', 37), ('もの', 37), ('なか', 32), ('ない', 32), ('彼', 32), ('彼女', 27), ('的', 26), ('墓', 26), ('なっ', 24), ('とき', 22), ('それ', 22), ('られ', 22)]\n",
      "単語の異なり数 1407\n",
      "総数 3798\n"
     ]
    }
   ],
   "source": [
    "data= open('hayasugiru_maiso.txt', 'r')\n",
    "textdata=data.read()#一括で詠み込む\n",
    "textdata = re.split('\\-{5,}', textdata)[0]+ re.split('\\-{5,}', textdata)[2]\n",
    "#詠み込んだ文章を---で囲われた部分とそれ以外で分割しタイトルと本文のみを取得\n",
    "textdata = re.split('底本', textdata)[0]\n",
    "#詠み込んだ文章を底本とそれ以外に分割し本文のみを取得\n",
    "textdata = re.split('［＃ここから', textdata)[0]\n",
    "\n",
    "mecab = MeCab.Tagger()\n",
    "lines = textdata.split(\"\\r\\n\")\n",
    "\n",
    "for line in lines:\n",
    "    r = []\n",
    "    # 学習に使わない表現の削除処理\n",
    "    s = line\n",
    "    s = s.replace(\"｜\", \"\")\n",
    "    s = s.replace('\\u3000', '')\n",
    "    s = re.sub(r'《.+?》', \"\", s)# 《》を消す\n",
    "    s = re.sub(r'［.+?］', '', s)#[]\n",
    "    s = re.sub(r'（.+?）', '', s)#()\n",
    "    # Mecab\n",
    "\n",
    "    node = mecab.parseToNode(s)#parseToNode()を使うと形態素の詳細情報\n",
    "    while node:\n",
    "        # 単語を取得\n",
    "        word = node.surface#surfaceで表層形\n",
    "        # 品詞を取得\n",
    "        part = node.feature.split(\",\")[0]#featureで形態素情報\n",
    "\n",
    "        if part in [\"名詞\", \"形容詞\", \"動詞\"]:#, \"記号\"\n",
    "             r.append(word)#リストに追加\n",
    "            \n",
    "        node = node.next\n",
    "    \n",
    "c = collections.Counter(r)#単語の出現個数をカウント\n",
    "print(\"各単語の出現回数\",c.most_common(20))#表示 most_common()メソッドに引数nを指定すると、出現回数の多いn要素のみを返す。\n",
    "print(\"単語の異なり数\",len(c))#重複しない要素（一意な要素）の個数（種類）をカウント\n",
    "print(\"総数\",len(r))#リストのサイズの取得(len関数)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#print(r)\n",
    "#print(lines)\n",
    "#textdata = textdata.strip()#stripメソッドで改行コードを取り除く\n",
    "#print(textdata)\n",
    "    #print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#bindata = open('carmen.txt', 'r').read()#,encoding=\"utf-8_sig\"\n",
    "#textdata = bindata.decode('shift_jis')\n",
    "\n",
    "#\"Shift-JIS\", \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write to a file\n",
    "w_file = \"ningen_result.txt\"\n",
    "with open(w_file, 'w', encoding='utf-8') as wf:\n",
    "    wf.write(\"\\n\".join(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
